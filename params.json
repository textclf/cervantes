{
  "name": "Cervantes",
  "tagline": "A deep learning text classification library over Keras",
  "body": "# Cervantes: Deep Learning library for text classification\r\n\r\n## Status: library working but still under heavy development / refactorization\r\n\r\nCervantes is a library built over [Keras](http://keras.io) that makes the process of using deep learning for text classification and sentiment analysis very easy. It includes basic deep architectures using word vectors, as well as complex models combining CNNs and RNNs over text hierarchies. Furthermore, it is built as a general framework where more advanced users can quickly experiment with new models without having to worry about data preprocessing.\r\n\r\nSome of the features offered by Cervantes:\r\n\r\n- allows creating models based on character and word vectors. \r\n- provides easily configurable data preprocessing and tokenization (using [spaCy](http://spacy.io)) so that it is easy to convert a text into an embedding that a neural network can use as input.\r\n- caters for any kind of users. Cervantes offers performant default classifiers that can be trained without any knowledge of Keras or deep learning. However, advanced users can easily create their own Keras models and connect them to the framework.\r\n-  allows for complex two-level hierarchical embeddings, computing word-sentence-text or character-word-text representations.\r\n\r\n## Quick example\r\n\r\nHere is a quick example showing how to train a bidirectional recurrent neural network for text classification:\r\n\r\n```python\r\nfrom cervantes.box import WordVectorBox\r\nfrom cervantes.language import OneLevelEmbedding\r\nfrom cervantes.nn.models import BiRNNClassifier\r\n\r\n# Create and build a word vector container from pre-computed vectors\r\nvbox = WordVectorBox(\"word_vectors.txt\")\r\nvbox.build()\r\n\r\n# Transform the training texts into a language embedding consisting of word vectors\r\nlang_embedding = OneLevelEmbedding(vbox, size=200)\r\nlang_embedding.compute_word_repr(train_texts + test_texts)\r\nlang_embedding.set_labels(train_labels + test_labels)\r\n\r\n# Instantiate and train a model using a bidirectional GRU over sequences of word vectors\r\nclf = BiRNNClassifier(lang_embedding, num_classes=2, unit='gru', \r\n                      rnn_size=64, train_vectors=True)\r\nclf.train(X=lembedding.data[:len(train_labels)],\r\n          y=lembedding.labels[:len(train_labels)])\r\n```\r\n \r\n\r\n------------------",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}